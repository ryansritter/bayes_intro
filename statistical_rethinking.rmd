---
title: "Statistical rethinking: The practical introduction to Bayesian statistics that actually made sense to me"
author: "Ryan S. Ritter | May 2023"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    theme: cosmo
    highlight: textmate
    number_sections: false
    code_folding: hide
editor_options: 
  markdown: 
    wrap: 72
---

```{r message=FALSE, warning=FALSE, include=FALSE}
### load libraries
library(tidyverse)
library(rstan)

### read in data set
Howell1 <- read_delim(
  "data/Howell1.csv", 
  delim = ";", 
  escape_double = FALSE, 
  trim_ws = TRUE
)
```

# Background

In grad school I was trained in frequentist statistics - which is great. Frequentist statistics are very useful. I'm not a hater*.

**Side note: I absolutely am a hater of the dichotomous decision making imposed by null hypothesis significance testing (NHST) and "statistical significance" (see [this great paper](https://www.nature.com/articles/d41586-019-00857-9)).*

For many years, however -- given my lack of any formal training in Bayesian methods -- whenever I encountered Bayesian statistics I had a hard time getting it.

When I started learning Bayesian statistics on my own, the best book I came across (by far!) was Richard McElreath's [Statistical Rethinking](https://github.com/rmcelreath/rethinking). Using very simple examples and applications in R code, he walks through the basics in a way that just made things click for me. 

The purpose of this notebook is to provide a similar practical introduction to the basics of Bayesian statistics in R -- using the same examples as in Statistical Rethinking -- but without relying on McElreath's `rethinking` R package.

I hope this helps others understand the basics of Bayesian statistics in the same way it did for me when I was first learning.

## Why Bayesian?

For me -- and I think for most people -- the most appealing thing about Bayesian statistics is that they allow for more intuitive statements to be made about the world. Frequentist stats can be hard to explain.

For example, in frequentist statistics we're stuck in a world where we have to talk about  $p(data|hypothesis)$ -- the probability of the data given the hypothesis. This paints us into an (often misinterpreted) corner when it comes to things like p-values and confidence intervals. For example: 

* **p-values:** The probability of observing this difference -- or a greater difference -- between two groups assuming the null hypothesis is true (i.e., we can't make a more intuitive statement about the probability of a given hypothesis being true).
* **95% confidence intervals:** If we were to repeat our experiment many times, we'd expect our confidence interval to contain the true population difference between the two groups 95% of the time... as for our specific confidence interval, we just kinda hope it's one of the 95% of CI's that does contain the true population difference but we're not sure (i.e., we can't make a more intuitive statement about there being a 95% chance that the true difference between groups is somewhere between [lower 95% CI] and [upper 95% CI]).

Bayesian statistics, on the other hand, flips this on its head. We get to talk about  $p(hypothesis|data)$ -- **the probability of the hypothesis given the data!**

* **Posterior:** Bayesian statistics result in a posterior distribution representing the relative plausibilities of different parameter values of interest, conditional on the data (i.e., we can say directly how likely it is that a given hypothesis about a parameter value is true).

* **Credibility Intervals:** Given the posterior distribution of a parameter value of interest, we know the probability that it falls within any given interval (i.e., we can say directly that there's a 95% chance that the parameter value of interest lies somewhere between [lower 95% CI] and [upper 95% CI]).

The rest of this notebook walks through the concepts of parameters/likelihood/priors and how to create posterior distributions from them -- first using an intuitive method known as grid approximation and then building on that intuition to understand sampling methods like Markov Chain Monte Carlo (MCMC).

# A simple motivating example

Let's start with a simple example where there is only 1 unknown parameter value of interest: the percent of the Earth that is covered in water.

Suppose you have a globe representing our planet, the Earth. We are
curious how much of the surface of this globe is covered in water, so we
adopt the following strategy: toss the globe in the air and catch it,
then record whether area under index finger is water (W) or land (L).
The first 9 samples look likea this:

**W L W W W L W L W (i.e., 6 out of 9 samples are water)**

What Bayesian statistics are going to allow us to do is calculate the plausibility of different values of our unknown parameter of interest (i.e., the percent of the Earth that is covered in water), given this data we've collected along with any prior beliefs we might have about how much of the Earth is covered in water.

